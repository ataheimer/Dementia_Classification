{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dementia Classification from MRI Images Using Machine Learning and Deep Learning Models\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88686dc754ae6672"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Alzheimer’s disease is a serious condition that affects millions of people around the world, especially older adults. It causes memory loss and confusion, making it hard for people to do everyday tasks. This disease is a major cause of dementia, and as the number of cases increases globally, it’s more important than ever to detect it early and accurately.\n",
    "\n",
    "In the field of machine learning and deep learning, various models have been developed to classify dementia levels from MRI images. The current best performance on this dataset, as reported on public platforms, is an accuracy of 98.7%. The main goal of this project is to break this record by developing a model that not only matches but exceeds this accuracy.\n",
    "\n",
    "To achieve this, we focused on classifying different levels of dementia using MRI images. We built models that can tell us if a person is Mild Demented, Moderate Demented, Non-Demented, or Very Mild Demented based on their MRI scans. We used various techniques like deep learning (CNNs) and machine learning, tested different ways to prepare the data, and combined the best methods into a final model that aims to outperform the current best accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db0d6c6dc892262e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "The dataset we used came from Kaggle ([Alzheimer MRI Disease Classification Dataset](https://www.kaggle.com/datasets/borhanitrash/alzheimer-mri-disease-classification-dataset)) and includes 6400 MRI images, divided into four categories:\n",
    "- **Mild Demented:** 896 images (724 for training, 172 for testing)\n",
    "- **Moderate Demented:** 64 images (49 for training, 15 for testing)\n",
    "- **Non-Demented:** 3200 images (2566 for training, 634 for testing)\n",
    "- **Very Mild Demented:** 2240 images (1781 for training, 459 for testing)\n",
    "\n",
    "### Data Format and Extraction Process\n",
    "The dataset was initially provided in Parquet format, which is a columnar storage file format that is efficient for large datasets but not directly usable for image processing. Therefore, we needed to extract the images from the Parquet file and save them as separate image files for further preprocessing and model training.\n",
    "\n",
    "To achieve this, we used a separate Python script named `Parquet_to_augmented.py`. This script:\n",
    "1. **Reads the Parquet file:** Loads the dataset, which contains image data stored as byte strings along with corresponding labels.\n",
    "2. **Converts byte strings to images:** Decodes the byte strings into images using OpenCV.\n",
    "3. **Saves the images into labeled folders:** Each image is saved in a corresponding folder based on its label, organizing the dataset into a structure suitable for training.\n",
    "\n",
    "### Purpose of the Extraction Script\n",
    "The script `Parquet_to_augmented.py` allowed us to:\n",
    "- **Organize images by their labels:** Images were extracted and saved into folders based on their labels, making it easier to handle them during preprocessing.\n",
    "- **Enable further processing:** By converting the Parquet data into standard image files, we could apply various data augmentation and manipulation techniques essential for model training.\n",
    "\n",
    "### Handling Dataset Imbalance\n",
    "The dataset is unbalanced, with many more images in some categories (like Non-Demented) compared to others (like Moderate Demented). This imbalance can make it harder for the model to learn to identify all categories accurately. To address this, we applied data augmentation techniques like rotation, shifting, and cropping, which helped create a more balanced dataset and improve model performance.\n",
    "\n",
    "This preprocessing step was critical in preparing the dataset for effective use in training deep learning models, ultimately enhancing the model’s ability to accurately classify different dementia levels.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78049f4d7741f281"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "### Data Exploration and Class Imbalance\n",
    "When we first looked at the original dataset, we noticed a big imbalance between the different categories. This imbalance could cause the model to favor the more common categories, like Non-Demented, and perform poorly on the less common ones, like Moderate Demented.\n",
    "\n",
    "To address this, we used several data augmentation techniques to create more examples for the underrepresented categories. This step is crucial because it helps the model learn to recognize all categories more accurately, not just the ones with more data.\n",
    "\n",
    "### Data Augmentation and Manipulation\n",
    "We used a variety of techniques to increase the number of training samples in the less common categories:\n",
    "- **Rotation:** We rotated the images at different angles to simulate different views of the brain.\n",
    "- **Shifting:** We moved the images slightly in different directions (up, down, left, right) to create variety.\n",
    "- **Brightness Adjustment:** We changed the brightness of the images to account for differences in MRI scan quality.\n",
    "- **Zooming:** We zoomed in on important parts of the brain to help the model focus on critical areas.\n",
    "- **Noise Addition:** We added random noise to some images to make the model more robust to variations in the data.\n",
    "\n",
    "These techniques helped us create a more balanced and diverse dataset. For example, rotation and shifting made it look like the images were taken from slightly different angles, which is important because in real-life scans, the brain might not always be perfectly centered. Brightness adjustment helped the model deal with variations in image quality, which is common in medical imaging.\n",
    "\n",
    "### Image Manipulation Based on Medical Insights\n",
    "We also made changes to the images based on what doctors typically look for when diagnosing Alzheimer’s. For instance, we focused on areas of the brain that are known to shrink (atrophy) as the disease progresses. By cropping out unnecessary parts of the image and enhancing the contrast in important areas like the hippocampus, we helped the model learn to focus on the most critical parts of the brain.\n",
    "\n",
    "This approach ensured that the model was looking at the same things a doctor would when trying to diagnose Alzheimer’s, which is essential for building a model that can perform well in real-world settings.\n",
    "\n",
    "### Datasets Used in the Project\n",
    "In this project, we used five different datasets, each involving specific preprocessing steps, to train and test our models. These datasets include various MRI images categorized into four classes: Mild Demented, Moderate Demented, Non-Demented, and Very Mild Demented.\n",
    "\n",
    "1. **Dataset #1: Original Images**\n",
    "   - **Description:** This dataset consists of the original, unaltered MRI images as provided in the Kaggle dataset.\n",
    "   - **Processing Steps:** No additional processing or manipulation was applied to these images.\n",
    "\n",
    "2. **Dataset #2: Original Images + Manipulation**\n",
    "   - **Description:** In this dataset, the original MRI images were manipulated to enhance the focus on key brain regions affected by Alzheimer’s disease.\n",
    "   - **Processing Steps:**\n",
    "     - **Manipulation:** The images were processed to emphasize areas where brain atrophy occurs, such as the hippocampus and cortical regions. This involved adjusting contrast and other image parameters to highlight these critical areas. **(Manipulation performed using `Combine_and_save.py`.)**\n",
    "\n",
    "3. **Dataset #3: Original Images + Data Augmentation + Cropping**\n",
    "   - **Description:** This dataset involves the original images with additional data augmentation and cropping to improve the model's ability to generalize.\n",
    "   - **Processing Steps:**\n",
    "     - **Data Augmentation:** Techniques such as rotation, shifting, brightness adjustment, zooming, and noise addition were applied to create more diverse training samples. **(Augmentation performed using `osman.ipynb`.)**\n",
    "     - **Cropping:** The images were cropped to remove unnecessary parts, focusing more on the brain areas most relevant to dementia classification. **(Cropping was performed within the code itself.)**\n",
    "\n",
    "4. **Dataset #4: Original Images + Manipulation + Data Augmentation**\n",
    "   - **Description:** This dataset combines the manipulation of key brain areas with data augmentation techniques to enhance the dataset.\n",
    "   - **Processing Steps:**\n",
    "     - **Manipulation:** Like in Dataset #2, the images were manipulated to highlight areas affected by atrophy. **(Manipulation performed using `Combine_and_save.py`.)**\n",
    "     - **Data Augmentation:** Various augmentation techniques were applied to increase the number of training samples and improve class balance. **(Augmentation performed using `osman.ipynb`.)**\n",
    "\n",
    "5. **Dataset #5: Original Images + Manipulation + Data Augmentation + Cropping**\n",
    "   - **Description:** This dataset includes the full set of processing steps—manipulation, data augmentation, and cropping—to create the most refined and focused training set.\n",
    "   - **Processing Steps:**\n",
    "     - **Manipulation:** Enhancements to highlight key brain areas. **(Manipulation performed using `Combine_and_save.py`.)**\n",
    "     - **Data Augmentation:** Techniques to diversify the dataset. **(Augmentation performed using `osman.ipynb`.)**\n",
    "     - **Cropping:** Focusing the images on critical brain regions by removing extraneous parts. **(Cropping was performed within the code itself.)**\n",
    "\n",
    "These datasets were used at different stages of the project to train and evaluate various models. By using multiple datasets with different levels of processing, we were able to explore different approaches to improving model performance, ultimately leading to a more robust and accurate classification of dementia levels.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7e8098eec6a3b65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Approaching\n",
    "\n",
    "### Testing with Pre-trained CNN Models\n",
    "After preparing the dataset, we began by testing several well-known Convolutional Neural Network (CNN) models that have been successful in other image classification tasks. These models include:\n",
    "- **VGG16:** A popular model known for its depth and accuracy in image recognition tasks.\n",
    "- **AlexNet:** One of the first deep learning models to demonstrate the superiority of CNNs over traditional methods in image classification.\n",
    "- **Unet:** Commonly used for segmenting medical images, tested here for classification purposes.\n",
    "- **ResNet34:** A deeper model that employs residual connections to enhance learning.\n",
    "- **DenseNet121:** A model that connects each layer to every other layer, facilitating feature reuse and improved learning.\n",
    "\n",
    "We trained and fine-tuned these models on our augmented dataset to determine which one would perform best. Despite their proven effectiveness in other scenarios, these pre-trained models fell short, particularly in accurately identifying the less common categories like Moderate Demented. This outcome suggested that these models were not fully suited to the specific characteristics of our dataset.\n",
    "\n",
    "### Custom Model Development and Transfer Learning Attempts\n",
    "Recognizing the limitations of the pre-trained models, we designed a custom Convolutional Neural Network (CNN) model, referred to as **Model 1**. This model was carefully tailored to address the challenges posed by our data, such as class imbalance and the need to detect subtle differences between various levels of dementia.\n",
    "\n",
    "Our custom model included the following key components:\n",
    "- **Convolutional Layers:** Extracted critical features from MRI images, such as edges, textures, and shapes indicative of dementia.\n",
    "- **Pooling Layers:** Reduced the dimensionality of the data, emphasizing significant features and decreasing computational complexity.\n",
    "- **Fully Connected Layers:** Combined the extracted features to classify the images into one of the four dementia categories.\n",
    "- **Batch Normalization and Dropout:** Techniques used to stabilize training and prevent overfitting, ensuring the model generalizes well to new data.\n",
    "\n",
    "Below is a visual representation of our custom CNN model architecture:\n",
    "\n",
    "<img src=\"CNNmodelGoruntu.jpg\" alt=\"Custom CNN Model Architecture\" width=\"800\" />\n",
    "\n",
    "### Transfer Learning and Feature Extraction\n",
    "Before finalizing the custom CNN model, we explored transfer learning by using a script named `transferLearning.py`, integrating the feature extraction capabilities of pre-trained models like AlexNet and VGG16:\n",
    "- **AlexNet Feature Extraction:** We used the convolutional layers of AlexNet as fixed feature extractors and added our own fully connected layers. This approach leveraged AlexNet's powerful feature detection while focusing our training efforts on the classification layers.\n",
    "- **VGG16 Feature Extraction:** Similarly, the convolutional base of VGG16, known for capturing intricate image details, was utilized. We froze these layers and adapted the model with custom layers for dementia classification.\n",
    "\n",
    "However, neither of these transfer learning approaches achieved the desired results. Although AlexNet and VGG16 provided a strong foundation, their features were not fully optimized for our MRI dataset. Consequently, we decided to refine our custom model further.\n",
    "\n",
    "### Training and Optimization Strategies\n",
    "With the architecture of the custom CNN model established, we concentrated on optimizing its training to enhance performance. Using the **Adam** optimizer, known for its adaptive learning rate mechanism, we fine-tuned the model through various training strategies:\n",
    "- **Adaptive Learning Rate with ReduceLROnPlateau Scheduler:** The learning rate was dynamically adjusted based on validation loss using the ReduceLROnPlateau scheduler. If the validation loss did not improve for several epochs, the learning rate was reduced by a factor, allowing the model to fine-tune its weights and prevent overshooting during training.\n",
    "\n",
    "- **AdamW Optimizer:** The AdamW optimizer was used, combining adaptive learning rates with weight decay regularization. This approach helped control overfitting by penalizing large weight updates while maintaining efficient learning dynamics.\n",
    "\n",
    "- **Early Stopping with Patience:** Early stopping was implemented to halt training if the validation loss did not improve for a defined number of epochs (patience). This strategy prevented overfitting and ensured that the best-performing model was saved.\n",
    "\n",
    "- **Batch Normalization and Dropout Regularization:** Batch normalization was applied after convolutional and fully connected layers to stabilize training and accelerate convergence by normalizing inputs within the network. Dropout layers were used to reduce overfitting by randomly deactivating neurons during training, encouraging the model to learn more generalized patterns.\n",
    "\n",
    "- **Evaluation and Metrics Calculation:** The model was evaluated using comprehensive metrics including accuracy, precision, recall, F1-score, IoU (Jaccard index), and AUC. This detailed evaluation provided insights into the model’s performance across different classes and guided further adjustments.\n",
    "\n",
    "- **Save Best Model:** The model's performance was continuously monitored, and the best version was saved based on validation loss improvements. This ensured that the final model used for testing was the one with optimal performance during training.\n",
    "\n",
    "\n",
    "These iterative experiments allowed us to fine-tune our custom model, systematically adjusting hyperparameters and training strategies to achieve the best possible performance. The final version of our custom CNN model significantly outperformed the pre-trained models, especially in distinguishing the more challenging categories like Moderate Demented, demonstrating the effectiveness of a tailored approach over standard transfer learning methods.\n",
    "\n",
    "This development process underscores the importance of custom model design and careful optimization, ultimately enabling us to build a robust classifier capable of accurately diagnosing different dementia levels from MRI images.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20196099bfa5154b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Initial Results\n",
    "\n",
    "The custom CNN model (Model 1) gave us promising results, showing that it could classify the MRI images more accurately than the pre-trained models. Specifically, it was better at distinguishing between the different levels of dementia, especially in the harder-to-classify categories like Moderate Demented.\n",
    "\n",
    "### Performance Metrics of Custom CNN Model (Model 1)\n",
    "Here are the results for Model 1 across the different datasets:\n",
    "\n",
    "- **Dataset #1:**\n",
    "  - **Loss:** 0.1217\n",
    "  - **Accuracy:** 0.9188\n",
    "  - **F1-Score:** 0.9179\n",
    "  - **Precision:** 0.9198\n",
    "  - **Recall (Sensitivity):** 0.9182\n",
    "\n",
    "- **Dataset #2:**\n",
    "  - **Loss:** 0.0588\n",
    "  - **Accuracy:** 0.9527\n",
    "  - **F1-Score:** 0.9529\n",
    "  - **Precision:** 0.9526\n",
    "  - **Recall (Sensitivity):** 0.9528\n",
    "\n",
    "- **Dataset #3:**\n",
    "  - **Loss:** 0.0506\n",
    "  - **Accuracy:** 0.9608\n",
    "  - **F1-Score:** 0.9609\n",
    "  - **Precision:** 0.9607\n",
    "  - **Recall (Sensitivity):** 0.9610\n",
    "\n",
    "- **Dataset #4:**\n",
    "  - **Loss:** 0.0336\n",
    "  - **Accuracy:** 0.9706\n",
    "  - **F1-Score:** 0.9705\n",
    "  - **Precision:** 0.9706\n",
    "  - **Recall (Sensitivity):** 0.9705\n",
    "\n",
    "- **Dataset #5:**\n",
    "  - **Loss:** 0.0228\n",
    "  - **Accuracy:** 0.9851\n",
    "  - **F1-Score:** 0.9851\n",
    "  - **Precision:** 0.9851\n",
    "  - **Recall (Sensitivity):** 0.9851\n",
    "\n",
    "These results demonstrate that our custom CNN model significantly outperformed the pre-trained models across all datasets. Notably, the model showed its best performance on Dataset #5, where it achieved an accuracy of 98.51%, highlighting its effectiveness in handling various data manipulations and augmentations.\n",
    "\n",
    "However, we wanted to push the performance even further. To do this, we decided to try a new approach: combining the image data with numerical data extracted from the MRI images. This hybrid approach aimed to use both the raw images and additional information to improve classification accuracy.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64dccf6b88288788"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Extracting Numerical Data\n",
    "\n",
    "### Feature Extraction from MRI Images\n",
    "In addition to using the images themselves, we extracted a wide range of numerical features from the MRI images to improve the classification accuracy. These features were selected based on their clinical relevance and their ability to capture important characteristics of brain structure and function. The extracted features included:\n",
    "\n",
    "- **Brain Volume (`brain_volume`):** Measures the total size of the brain, often decreasing as Alzheimer’s progresses.\n",
    "- **Cerebrospinal Fluid Volume (`csf_volume`):** The volume of cerebrospinal fluid surrounding the brain, which increases as the brain shrinks.\n",
    "- **Gray Matter Volume (`gray_matter_volume`):** The amount of gray matter, essential for processing information, often reduced in dementia patients.\n",
    "- **White Matter Volume (`white_matter_volume`):** White matter changes can indicate disruption in brain connectivity.\n",
    "- **Maximum Intensity (`max_intensity`):** The brightest pixel in the image, which can highlight regions of interest.\n",
    "- **Mean Intensity (`mean_intensity`):** The average pixel intensity, reflecting overall brightness levels.\n",
    "- **Standard Deviation of Intensity (`std_intensity`):** Measures the variability in pixel brightness, providing insights into image texture.\n",
    "- **Contrast (`contrast`):** Measures differences in intensity, reflecting image texture and tissue differences.\n",
    "- **Energy (`energy`):** Indicates the uniformity of texture, which can reflect the overall consistency of tissue types.\n",
    "- **Homogeneity (`homogeneity`):** Measures how similar or consistent the texture is throughout the image.\n",
    "- **Entropy (`entropy`):** Quantifies the amount of disorder or randomness in the image, often linked to tissue irregularities.\n",
    "- **Area (`area`):** The extent of the brain covered by the image, providing a measure of the brain’s visible size.\n",
    "- **Skewness (`skewness`):** Measures the asymmetry of pixel intensity distribution, which can indicate abnormal tissue distribution.\n",
    "- **Kurtosis (`kurtosis`):** Describes the peakedness of the intensity distribution, often reflecting the presence of sharp changes in tissue properties.\n",
    "- **Fractal Dimension (`fractal_dim`):** Captures the complexity of the image, measuring how detailed the brain structure appears.\n",
    "- **Temporal Lobe Volume (`temporal_lobe`):** Measures the average intensity in the temporal lobe, a critical area affected in Alzheimer’s.\n",
    "- **Hippocampus Volume (`hippocampus`):** Focuses on the hippocampus, which is crucial for memory and one of the first areas impacted by Alzheimer’s.\n",
    "- **Neuron Density (`neuron_density`):** Estimates the density of neurons, reflecting brain cell health and distribution.\n",
    "- **Total Neurons (`total_neurons`):** Total neuron count, providing an overall measure of brain cell quantity.\n",
    "- **Occipital Lobe Volume (`occipital_lobe`):** Measures the average intensity in the occipital lobe, which is involved in visual processing.\n",
    "- **Frontal Lobe Volume (`frontal_lobe`):** Captures the frontal lobe’s average intensity, linked to cognitive and decision-making functions.\n",
    "- **Insular Lobe Volume (`insular_lobe`):** Measures average intensity in the insular lobe, associated with emotion and cognitive functions.\n",
    "- **Thalamus Volume (`thalamus`):** Indicates the intensity within the thalamus, which acts as a relay center for sensory and motor signals.\n",
    "- **GLN (`gln`), SRE (`sre`), LRE (`lre`), HGRE (`hgre`), LGRE (`lgre`), RP (`rp`), RLN (`rln`):** These are various texture and statistical features calculated from the gray level co-occurrence matrix (GLCM), which measure the spatial relationship of pixels. They provide additional information about the image texture, highlighting differences between normal and abnormal tissue.\n",
    "- **Label (`label`):** The ground truth class label for each image, which is essential for training and evaluating the model.\n",
    "\n",
    "These features were carefully chosen to encapsulate a wide range of information about the brain's structure, intensity, and texture, allowing the model to leverage both visual and numerical data for improved classification accuracy.\n",
    "\n",
    "### Preparing the Dataset\n",
    "To extract these features, we followed a structured and rigorous process:\n",
    "\n",
    "1. **Brain Segmentation:**\n",
    "   - **Objective:** To isolate the brain from other structures in the MRI images, focusing the analysis on relevant areas.\n",
    "   - **Method:** We employed segmentation algorithms that used thresholding and contour detection to precisely separate brain tissues, ensuring accurate volume and intensity measurements.\n",
    "\n",
    "2. **Feature Calculation:**\n",
    "   - Each feature was calculated using specialized algorithms designed to quantify aspects of the brain relevant to dementia diagnosis. For example, intensity-based features like mean and maximum intensity were computed directly from pixel values, while volume measurements relied on the segmented areas of the brain.\n",
    "\n",
    "3. **Data Compilation:**\n",
    "   - All extracted features were compiled into a CSV file, with each row representing a single MRI image and each column corresponding to a specific feature. This structured data format made it easier to integrate these features with the visual data during the training phase.\n",
    "\n",
    "### Utilizing the Numerical Data\n",
    "The structured dataset of numerical features was used alongside the MRI images during model training. By incorporating these quantitative measures, the model gained access to a deeper layer of information, allowing it to make more nuanced and accurate predictions about dementia severity. This approach aligns with clinical practices, where doctors often rely on a combination of visual assessments and quantitative measurements to diagnose Alzheimer's disease.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dde578e666671521"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. ANN Model Development\n",
    "\n",
    "### Evaluating Pre-trained Machine Learning Models\n",
    "With the numerical data ready, we tested several pre-trained machine learning models to see how well they could classify dementia levels based on these features. The models we tested included:\n",
    "- **XGBoost:** A powerful algorithm that is often used for tasks involving structured data.\n",
    "- **LightGBM:** A fast and memory-efficient algorithm similar to XGBoost.\n",
    "- **RandomForest:** A method that creates multiple decision trees and combines them to make better predictions.\n",
    "- **CatBoost:** An algorithm that is particularly good at handling categorical data.\n",
    "\n",
    "Despite their strengths, these pre-trained models didn’t perform as well as expected, especially in distinguishing between the different levels of dementia. This led us to develop a custom Artificial Neural Network (ANN) model that could better handle the complexity of our numerical data.\n",
    "\n",
    "### Creating a Custom ANN Model\n",
    "Since the pre-trained models didn’t meet our needs, we built a custom ANN model (**Model 2**) specifically designed to process the numerical features extracted from the MRI images. This model was developed to take advantage of the structured data, enhancing the classification accuracy and providing deeper insights into the relationship between features and dementia levels.\n",
    "\n",
    "**Architecture Overview:**\n",
    "- **Input Layer:** The model starts with an input layer that takes in the numerical features, allowing it to handle a diverse range of inputs from brain volumes to intensity measurements.\n",
    "- **Hidden Layers:** The network consists of multiple fully connected hidden layers, each designed to learn complex relationships between the input features. Batch normalization was applied after each layer to stabilize learning, and dropout was used to prevent overfitting by randomly disabling neurons during training.\n",
    "- **Output Layer:** The final layer outputs probabilities for each of the four dementia categories, translating the model’s learned features into actionable classifications.\n",
    "\n",
    "Below is a visual representation of our custom ANN model architecture:\n",
    "\n",
    "<img src=\"ANNmodelGoruntu2.jpg\" alt=\"Custom ANN Model Architecture\" width=\"1000\" />\n",
    "\n",
    "**Training and Optimization Strategies:**\n",
    "- **Adaptive Learning Rate (Cyclic Learning Rate):** A cyclic learning rate strategy was employed to dynamically adjust the learning rate during training, enabling the model to escape local minima and converge more effectively. This strategy was critical for maintaining training momentum and refining the model’s performance.\n",
    "- **Dropout Regularization:** Dropout layers were strategically placed between the fully connected layers to mitigate overfitting. This approach forced the model to learn more generalized patterns by preventing over-reliance on specific pathways within the network.\n",
    "- **Batch Normalization:** Each hidden layer was followed by batch normalization, which normalized the inputs of each layer, accelerating training and improving convergence.\n",
    "- **Weight Decay Regularization:** The AdamW optimizer, which combines adaptive learning rates with weight decay, was used to further regularize the model. This method minimized overfitting by controlling the complexity of weight adjustments, maintaining a balance between learning and generalization.\n",
    "\n",
    "**Performance Insights:**\n",
    "- The custom ANN model demonstrated superior performance compared to the pre-trained models, effectively handling the structured numerical data and yielding higher classification accuracy.\n",
    "- The dynamic learning rate and regularization techniques were crucial in adapting the model to the complexities of the data, ensuring rapid convergence and robust performance.\n",
    "- The model’s success highlighted the importance of custom neural network architectures tailored specifically to the data’s characteristics, particularly in complex medical datasets.\n",
    "\n",
    "**Conclusion:**\n",
    "The custom ANN model proved to be a valuable tool in classifying dementia levels, especially when combined with the CNN model based on image data. This integration of numerical and visual information provided a comprehensive approach, enhancing the overall classification performance and offering deeper insights into dementia diagnosis using AI.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447b198835947a33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. ANN and CNN Fusion Model\n",
    "\n",
    "### Concept and Implementation\n",
    "To achieve the highest classification accuracy, we developed a hybrid fusion model that combines the strengths of both the custom CNN and ANN models. This approach uses both the image data from the CNN and the numerical data from the ANN, creating a more powerful model than either could achieve alone.\n",
    "\n",
    "#### Data Merging and Indexing\n",
    "We carefully merged the image data and the numerical data based on unique identifiers, ensuring that each MRI image was correctly paired with its associated numerical features. This accurate indexing allowed seamless integration of insights from both data types.\n",
    "\n",
    "#### Fusion Strategy\n",
    "The fusion model processes the two data types through their respective models:\n",
    "- **CNN Model:** Processes the MRI images, extracting spatial features and making predictions based on visual data.\n",
    "- **ANN Model:** Handles the numerical features from the CSV file, generating predictions from quantitative data.\n",
    "\n",
    "The fusion strategy combined the predictions from both models in various ways:\n",
    "- **75% CNN - 25% ANN:** This approach weighted the CNN’s predictions more heavily, leveraging the visual strengths of the CNN while incorporating insights from the ANN.\n",
    "- **50% CNN - 50% ANN:** An equal weighting strategy that balanced contributions from both models, making the final prediction based on a blend of visual and numerical data insights.\n",
    "\n",
    "Below is the visual representation of the fusion model architecture:\n",
    "\n",
    "<img src=\"FusionModel.jpg\" alt=\"Fusion Model Architecture\" width=\"1000\" />\n",
    "\n",
    "### Achieving Record Performance\n",
    "The hybrid fusion model consistently outperformed both the CNN and ANN models individually. The 50%-50% fusion strategy proved most effective, achieving the highest metrics across all datasets, particularly excelling in the more challenging dementia classification categories.\n",
    "\n",
    "This fusion model demonstrates the power of combining visual and numerical data, highlighting how hybrid approaches can significantly enhance the performance of deep learning models in complex medical classification tasks.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed1a450b71cb68b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Final Results\n",
    "\n",
    "In this section, we present the performance metrics for all the models tested, including the custom CNN, custom ANN, and the fusion model. The results compare their accuracy, precision, recall, and F1-score across different datasets.\n",
    "\n",
    "### Key Findings\n",
    "- **Custom CNN Model:** Demonstrated significant improvement over pre-trained models, especially in accurately identifying the less common dementia categories.\n",
    "- **Custom ANN Model:** Showed strong classification performance on the numerical data, complementing the CNN’s visual analysis capabilities.\n",
    "- **Fusion Model:** \n",
    "  - **Performance Overview:** The fusion model achieved the best overall performance, consistently outperforming the individual CNN and ANN models. The optimal 50%-50% fusion weighting delivered the highest accuracy, F1-score, precision, and recall, setting new benchmarks for dementia classification.\n",
    "  - **Final Results:** The fusion model reached an accuracy of 0.9986 and an F1-score of 0.9985 on Dataset #4, demonstrating the effectiveness of combining visual and numerical data. This balanced approach provided robust, reliable predictions across all datasets.\n",
    "\n",
    "### Conclusion\n",
    "The fusion model's success highlights the power of integrating diverse data types for complex classification tasks. By blending the CNN’s visual strengths with the ANN’s numerical insights, the fusion approach aligns closely with clinical diagnostic practices, where both visual inspection and quantitative analysis are used to assess dementia severity. This hybrid model not only achieved record-setting accuracy but also enhanced the overall interpretability and reliability of the classification results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e55965cf16ec2b5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This project demonstrated that integrating deep learning (CNN) with traditional machine learning (ANN) can significantly enhance the classification of dementia levels in Alzheimer’s disease using MRI images. The development of custom models tailored to the unique characteristics of visual and numerical data, followed by a sophisticated fusion strategy, led to significantly improved performance compared to using pre-trained models alone.\n",
    "\n",
    "The fusion model, in particular, showcased the power of combining diverse data types, setting new benchmarks in dementia classification accuracy. By merging insights from both image-based and numerical features, the hybrid approach not only achieved record-setting results but also provided a comprehensive, clinically relevant tool for diagnosing dementia.\n",
    "\n",
    "### Future Work\n",
    "This study opens up several avenues for further research and development:\n",
    "- **Expanding the Dataset:** Testing the model on larger, more diverse datasets, including multi-center studies with different imaging protocols, to enhance its robustness and generalizability across broader populations.\n",
    "- **Exploring Other Fusion Strategies:** Investigating more advanced fusion techniques, such as neural attention mechanisms or dynamic weighting based on input characteristics, to further optimize the balance between the CNN and ANN contributions.\n",
    "- **Real-world Application:** Translating the fusion model into a practical tool for clinical settings, potentially integrating it into radiology workflows to assist doctors in diagnosing and managing Alzheimer’s disease more effectively. This could involve developing a user-friendly interface and validating the model in real-world clinical trials.\n",
    "\n",
    "### Final Thoughts\n",
    "This study provides a strong foundation for future research in medical image classification, particularly for complex diseases like Alzheimer’s. By demonstrating the benefits of combining deep learning with traditional machine learning, this work paves the way for more advanced diagnostic tools that leverage the best of both worlds. The fusion approach outlined here not only improves classification accuracy but also enhances the interpretability and reliability of AI-driven medical decisions, making it a valuable asset in the ongoing fight against neurodegenerative diseases.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee652531c36319f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
